---
title: "Бајесовска линеарна регресија"
author: "Александра Здравковић, Огњен Лазић, Коста Љујић, Михајло Србакоски"
date: "септембар 2020"
output: 
    prettydoc::html_pretty:
      theme: architect
      highlight: github
reference: reference.bib 
---
<style>
body {
text-align: justify}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Увод

Баjeсова статистика је теорија у пољу статистике заснована на бајесовском тумачењу вероватноће, где вероватноћа мери степен веровања у неки догађај. Тај степен веровања може се заснивати на претходном знању истраживача о догађају, као што су резултати претходних експеримената, или на личним уверењима о догађају. Овакав поглед се знатно разликује од фреквенционистичке интерпретације која вероватноћу посматра као границу релативне учесталости догађаја након много понављања експеримента.

Бајесове статистичке методе користе Бајесову формулу за израчунавање и ажурирање вероватноће након добијања нових података. Као што ћемо формално и видети, Бајесова формула описује условну вероватноћу догађаја на основу података, као и претходних информација или веровања о догађају. На пример, у бајесовском закључивању, Бајесова формула може се користити за оцену параметара дате расподеле вероватноћа.

Бајесовска анализа заснива се на почетном скупу претпоставки и омогућава истраживачима да у процес закључивања као додатак подацима којима располажу укључе и поуздане информације које већ поседују. Закључци о непознатим параметрима нису изражени на уобичајен начин, тј. као тачкаста оцена са својим интервалом поверења. Уместо тога, непознати параметри имају своју расподелу, тј. могу се сматрати случајним величинама. Пре посматрања података непознати параметри имају своју априорну расподелу која осликава априорно знање истраживача - информације које су доступне пре него што узмемо у обзир добијене податке. Након узимања података у обзир добија се апостериорна расподела.
Апостериорна расподела затим може послужити за извођење разних закључка о непознатом параметру као што су: квантили расподеле, вероватноћа да параметар узима вредности из неког интервала, затим интервали прекривања који представљају бајесовски аналогон интервалима поверења као и многи други.
Основе бајесовског закључивања могу се свести на три корака:

1. Спецификовање вероватносног модела који укључује функцију веродостојности и априорну расподелу непознатог параметра.

2. Ажурирање знања о непознатом параметру рачунањем условне расподеле непознатог параметра при услову да су нам дати ти конкретни подаци. Ту расподелу зовемо апостериорном расподелом параметра.

3. Процена (евалуација) колико модел одговара подацима.

Уколико је неопходно, модел се може изменити, а затим се могу поновити ова три основна корака. Ови кораци се могу поновити и након добијања нових података, при чему за априорну расподелу изаберемо претходно добијену апостериорну расподелу.

# Бајесовска статистика{#id1}

У овом поглављу дат је преглед на теоријски материјал потребан за бајесовско закључивање у општем смислу, као и за бајесовски приступ линеарној регресији.
Биће приказани:

* [Бајесовска статистика](#id1)
  + [Бајесов метод оцењивања параметара](#id2)
    - [Тачкасте оцене](#id3)
    - [Интервалне оцене](#id4)
* [Монте Карло методе засноване на ланцима Маркова](#id5)
  + [Метрополис-Хастингс алгоритам](#id6)
  + [Гибсов алгоритам](#id7)
* [Евалуација и избор модела](#id8)

Бајесово правило описује вероватноћу догађаја засновану на априорном знању о условима који могу бити повезани са тим догађајем.

Бајесово правило гласи:

$$
\begin{aligned}
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
\end{aligned}
$$
где су $A$ и $B$ догађаји такви да $P(B) \neq 0.$ Ako je $\{A_j\}$ разбијање сигурног догађаја на дисјунктне, онда применом формуле жа потпуну вероватноћу добијамо:

$$
\begin{aligned}
P(A|B) = \frac{P(B|A)P(A)}{\sum_{j}{P(B|A_j)P(A_j)}}
\end{aligned}
$$

Као што смо рекли, у бајесовској интерпретацији вероватноћа мери степен веровања. Бајесова теорема тада служи као веза између степена веровања да ће се
десити догађај $А$ пре и после узимања у обзир догађаја $B$ . У том контексту $P(A)$ називамо априорном вероватноћћом и она представља почетни степен веровања у $A$. $P(A|B)$ зовемо апостериорна вероватноћа и за њено добијање нам je, поред априорне $P(A)$, потребнa још и условна вероватноћа догађаја $B$ - $P(B|A)$, као и и $P(B)$. Једина улога $P(B)$ као имениоца у Бајесовом правилу је да обезбеди нормираност и зато можемо
да запишемо:

$$
\begin{aligned}
P(A|B) \propto P(B|A)P(A)
\end{aligned}
$$
Условна веротноћа $P(A|B)$ је баланс онога у шта смо већ веровали - $P(A)$, и доприноса добијеног од нове
опсервације - $P(B|A)$. Постоје ситуације када су подаци утицајнији од априорног знања, као и обрнуто. То нам одговара јер када немамо довољно података или су они лошег квалитета пожељно је да се ослонимо
што више на претходна знања. С друге стране, уколико имамо довољно података априорна знања нису од великог интереса.

Бајесово правило можемо применити и на случајне променљиве $X, Y$. Постоје многе ситуације у којима желимо да знамо X али можемо да меримо само величину Y која је на неки начин повезана са њом. 

* Променљиве $X, Y$ апсолутно-непрекидног типа 

Условну густину за $X$ можемо изразити као количник:
$$
\begin{aligned}
f_{X|Y}(x|y) = \frac{f_{Y|X}(y|x)f_X(x)}{f_Y(y)}\\
=\frac{f_{Y|X}(y|x)f_X(x)}{\int_{-\infty}^{\infty}f_{Y|X}(y|x)f_X(x)du}
\end{aligned}
$$

* Променљиве $X, Y$ дискретног типа

Са $P_X(x)$ означимо вероватноћу догађаја ${X = x}$. Тада важи:
$$
\begin{aligned}
P_{X|Y}(x|y) = \frac{P_{Y|X}(y|x)P_X(x)}{P_Y(y)}\\
=\frac{P_{Y|X}(y|x)P_X(x)}{\sum_{k}P_{Y|k}(y|k)P_X(k)}
\end{aligned}
$$


## Бајесов метод оцењивања параметара{#id2}

Нека је $\theta$ непознати параметар који желимо да анализирамо. Као што смо већ напоменули, у Бајесовој статистици се параметар $\theta$ сматра величином чија се променљивост може описати расподелом вероватноће. Ту расподелу називамо __априорна расподела__ и обележавамо $\pi(\theta)$.
Та расподела је субјективна расподела која одражава веровање истраживача да се $\theta$ налази у неком подскупу скупа $\Theta$, тј. заснована је да његовом претходном знању и одређује се пре него што се узорак извуче. Узорачка расподела $f(\textbf{x}|\theta)$ се сматра условном расподелом података под условом да је параметар $\theta$ узео неку вредност. На основу ових расподела, које чине бајесовски модел, рачуна се условна расподела параметра $\theta$ у односу на узорак $\textbf{x}$, коју називамо __апостериорна расподела__. Апостериорна расподела представља расподелу за $\theta$, ажурирану подацима из узорка.

Нека је $\textbf{X}$ узорак са заједничком густином (или законом) расподеле $f(\textbf{x}|\theta)$, где је $\theta \in \Theta$. Нека је $\pi(\theta)$ априорна расподела пре извачења узорка. Апостериорна расподела дефинише се Бајесовом формулом
$$
\begin{aligned}
\pi(\theta|\textbf{x}) = \frac{f(\textbf{x}|\theta)\pi(\theta)}{\int_{\Theta}f(\textbf{x}|\theta)\pi(\theta)d\theta}
\end{aligned}
$$
Именилац израза често зовемо _нормирајућа константа_, јер не зависи од $\theta$, те можемо записати
$$
\begin{aligned}
\pi(\theta|\textbf{x}) = K(\textbf{x})f(\textbf{x}|\theta)\pi(\theta) \propto f(\textbf{x}|\theta)\pi(\theta)
\end{aligned}
$$

Апостериорна расподела описује варијабилност параметра $\theta$ након добијања података из узорка, узимајући у обзир и априорну расподелу. Ту имамо суштинску разлику у односу на класичну статистику. У Бајесовој статистици све информације о $\theta$ налазе се у апостериорној расподели, што значи да она зависи искључиво од реализованог узорка (преко функције веродостојности) и априорне расподеле. Из апостериорне расподеле изводе се даље сви закључци у вези са параметром $\theta$ (оцене, интервали, тестови). 
Уколико је циљ анализе оценити непозанте параметре, постоје две основне групе: тачкасте и интервалне оцене.

### Тачкасте оцене{#id3}

Са $L(\theta, \hat{\theta}(\textbf{x}))$ је означена __функција губитака__ која мери одступање стварне
вредности непознатог параметра од његове оцењене вредности. 

Најчешће коришћене функције губитака:

1. $L(\hat{\theta}, \theta) = (\hat{\theta} - \theta)^2$. Бајесова оцена је једнака очекивању апостериорне расподеле.
2. $L(\hat{\theta}, \theta) = |\hat{\theta} - \theta|$. Бајесова оцена је једнака медијани апостериорне расподеле.
3. $L(\hat{\theta}, \theta) = I\{|\hat{\theta} - \theta|\geq \delta \}$. Бајесова оцена је једнака моди апостериорне расподеле.

За функцију губитака $L$ и оцену $\hat{\theta}$, __функција ризика__ је дефинисана као
$$
\begin{aligned}
R_{\theta}(\hat{\theta}) = E_{\theta}L(\hat{\theta}, \theta) = \int_{\mathcal{X}}L(\hat{\theta}, \theta)f(\textbf{x};\theta)d\textbf{x}
\end{aligned}
$$
__Бајесов ризик__, као функција од $\hat{\theta}$, дефинише се као очекивана вредност функције губитка, где је очекивање у односу на априорну расподелу параметра $\theta$, тј.
$$
\begin{aligned}
R_{B}(\hat{\theta}) = \int_{\Theta}R_{\theta}(\hat{\theta})\pi(\theta)d\theta
\end{aligned}
$$
Овако дефинисан ризик не зависи од вредности параметра и самим тим омогућавалако поређење оцена. 
__За оптималну Бајесову оцену узима се она која минимизује Бајесов ризик__. Пошто важи
$$
\begin{aligned}
R_{B}(\hat{\theta}) = \int_{\mathcal{X}}\left(\int_{\Theta}R_{\theta}(\hat{\theta})\pi(\theta)d\theta\right)\mathcal{Q}(\textbf{x})d\textbf{x}
\end{aligned}
$$
где је $\mathcal{X}$ узорачки простор, а $\mathcal{Q}(\textbf{x})$ маргинална расподела за $\mathbf{X}$, оптимална оцена $\hat{\theta}$ је она која минимизује
$$
\begin{aligned}
R(\hat{\theta}) = \int_{\Theta}L(\hat{\theta}, \theta)\pi(\theta|\textbf{x})d\theta
\end{aligned}
$$
Овај израз назива се __апостериорни средњи ризик__. Дакле, оптимална Бајесова оцена је она која минимизује математичко очекивање функције губитака у односу на апостериорну расподелу (самим тим она ће миними-зовати и априорни средњи ризик).

### Интервалне оцене{#id4}

Интервалне оцене се називају интервали прекривања и представљају бајесовски аналогон фреквенционистичким интервалима поверења. За задату вредност $\alpha$, $100(1 - \alpha)\%$ интервал прекривања даје област параметарског простора у коме је вероватноћа покривања $\theta$ једнака $1 - \alpha$.
Интервал прекривања за апостериорну расподелу можемо дефинисати као скуп $C$, подскуп параметарског простора $\Theta$ за кога важи:
$$
\begin{aligned}
\int_{C}\pi(\theta|\textbf{x})d\theta = 1 - \alpha
\end{aligned}
$$
у случају апсолутно-непрекидног параметра $\theta$, док интеграл мењамо сумом, а знак једнакости знаком веће или једнако у случају дискретног параметра. Тако дефинисани интервали нису јединствени, јер можемо
дефинисати скуп $C$ на разне начине тако да претходна једнакост важи.

Специјално, уколико желимо да креирамо интервале са једнаким реповима, то постижемо тако што су апостериорне вероватноће да вредност параметра буде лево и десно од интервала једнаке и износе по $\frac{\alpha}{2}$.
У случају симетричних расподела овако дефинисан интервал веродостојности биће центриран око средње вредности.

Други специјални случај интервала прекривања је __интервал највеће апостериорне густине__, тј. __ИНАГ__. Додатни услов је да је густина унутар интервала увек већа или једнака од густине ван њега. Уколико је апостериорна расподела вишемодална, ИНАГ ће заправо бити унија интервала. У случају унимодалне и симетричне апостериорне расподеле интервал прекривања са једнаким реповима и ИНАГ се поклапају.



# Монте Карло методе засноване на ланцима Маркова{#id5}

Markov Chain Monte Carlo (MCMC) је метода за добијање информација о расподелама, посебно за процену апостериорних расподела у Бајесовском приступу. 

Markov Chain Monte Carlo (MCMC) методе обухватају класу алгоритама за узорковање из расподеле вероватноћа када је директно узорковање тешко. Добијени узорак се може користити за апроксимирање расподеле (нпр. за генерисање хистограма) или за израчунавање интеграла (нпр. очекивана вредност). Конструисањем ланца Маркова који има нашу жељену расподелу као стационарну расподелу, може се добити узорак из жељене расподеле посматрањем ланца након одређеног броја корака (што је више корака расподела је ближа стварној расподели која нас интересује).

Подсетимо се, $\textit{ланац Маркова}$ је уређен, индексиран скуп случајних величина (стохастички процес) где вредност сваке величине вероватносно зависи само од претходне вредности. Конкретно, ланац $\{X_t | t \in \mathbb{R}\}$ је ланац Маркова акко има Марковско својство, тј. за њега важи
$$
\begin{aligned}
P\{X_t \in \mathcal{A}|X_0, X_1, ...,X_{t-1}\} = P\{X_t \in \mathcal{A}\} 
\end{aligned}
$$
MCMC методе се првенствено користе за нумеричку апроксимацију вишедимензионалних интеграла. Нама ће од највећег значаја бити њихова примена у бајесовској статистици. Знамо да у многим случајевима апостериорна расподела често нема једноставну препознатљиву форму и захтева рачунање компликованих интеграла, тако да из ње не можемо узорковати коришћењем уграђених $R$, али ћемо то моћи урадити помоћу Markov Chain Monte Carlo методе.
На пример, можемо проценити било које очекивање апостериорне расподеле док год имамо $N$ симулираних узорака из те расподеле као:
$$
\begin{aligned}
E[f(x)]_P \approx \frac{1}{N}\sum_{i=1}^{N}f(x{(i)})
\end{aligned}
$$
где је $P$ апостериорна расподела, $f(x)$ жељена величина чије очекивање нас интересује, а $f(s^{(i)})$, је њена вредност на $i$-том симулираном узорку из расподеле $P$. 

У пракси, ланац се постепено креира тако што се почне од скупа тачака произвољно одабраних и довољно удаљених. Затим се креира ланац тако што се предлажу нова стања и одлучује се да ли ће се она прихватити или не. Ови ланци су стохастички процеси који се крећу по узорачком простору на случајан начин, али тако да је већа вероватноћа да ће тачке у регионима велике вероватноће бити прихваћене. 

Ови алгоритми стварају ланце Маркова, такве да имају равнотежну расподелу која је пропорционална датој функцији. Обично није тешко конструисати Марковљев ланац са жељеним својствима. Већи проблем је одредити колико је корака потребно за конвергенцију стационарној расподели унутар прихватљиве грешке. Добар ланац ће имати ,,брзо мешање”, тј. стационарна расподела ће се брзо достизати почевши од произвољне позиције.

MCMC методe које ћемо ми користити су:
  
* [Метрополис-Хастингс алгоритам](#id6)

Овај метод генерише ланац Маркова користећи одређену густину предлога за предлагање нових корака који се онда прихватају или одбацују са одређеном вероватноћом. Ово је најопштији алгоритам, али постоји много унапређења и новијих алтернатива које се на њега надограђују.

* [Гибсов алгоритам](#id7) 

Да бисмо користили овај метод, потребно је да можемо тачно да узоркујемо из свих условних расподела наше жељене расподеле. Гибсово узорковање је популарно, јер не захтева подешавање расподеле предлога. Постоје многа побољшања и овог метода.

## Метрополис-Хастингс алгоритам{#id6}

#### Идеја

Рецимо да желимо да вадимо узорке из расподеле вероватноћа $f(x)$, међутим не можемо то да урадимо, јер је директно узорковање тешко. Оно што прво пада на памет је да покушамо некако да апроксимирамо.

Метрополис-Хастингс каже да ако знамо како да рачунамо вредности неке функције $\tilde{f}(x)$ која је пропорционална расподели $f$, моћи ћемо и да извадимо узорке из наше циљне расподеле. Чињеница да је потребно да $\tilde{f}(x)$ буде само пропорционална жељеној густини, не и једнака, у потпуности нам одговара у случају бајесовског приступа, јер је рачунање нормализационе константе обично највећи проблем када нам је циљна расподела апостериорна расподела параметара од интереса.

Идеја која стоји иза Метрополис-Хастингс алгоритма је да симулира ланац Маркова у простору стања тако да стационарна расподела ланца буде циљна расподела. Код традиционалних анализа ланаца Маркова обично су дате вероватноће прелаза, а непозната је стационарна расподела, док је код MCMC ланаца позната равнотежна расподела, а вероватноће прелаза се описују тако да се та равнотежа постигне.

У MCMC алгоритмима уобичајено је да се користе реверзибилни ланци Маркова.
Ланац Маркова је реверзибилан ако задовољава $\textit{detailed balance}$ услов, тј. ако
$$
\begin{aligned}
\pi_i \cdot p_{ij} = \pi_j \cdot p_{ji}
\end{aligned}
$$

где је $p_{ij} = P(X_n = j|X_{n-1} = i)$ вероватноћа прелаза из стања $i$ на стање$j$, а $\pi_i$ и $\pi_j$ су вероватноће да ланац у равнотежном стању буде у стању $i$, односно $j$.
Користе се баш реверзибилни ланци, јер ће из важења $\textit{detailed  balance}$ услова за жељену расподелу следити да је ланац Маркова конструисан тако да му је баш та расподела стационарна расподела. 

Према томе, Метрополис-Хастингс алгоритам укључује креирање Марковског процеса (конструисањем вероватноћа прелаза) који задовољава горњи услов, тако да је његова стационарна расподела $\pi$ баш наша жељена расподела $f$.

Почињемо првим условом - $\textit{detailed balance}$. Дакле, треба да важи да је:
$$
\begin{aligned}
\pi(x) \cdot p_{xy} = \pi(y) \cdot p_{yx}
\end{aligned}
$$
односно
$$
\begin{aligned}
f(x) \cdot p_{xy} = f(y) \cdot p_{yx}
\end{aligned}
$$
Даље добијамо
$$
\begin{aligned}
\frac{f(y)}{f(x)} = \frac{p_{xy}}{p_{yx}}
\end{aligned}
$$

Сада вероватноће прелаза са стања $x$ на стање $y$, и обрнуто, можемо раздвојити на два дела: предлог новог стања и вероватноћа прихватања или одбијања, тј.
$$
\begin{aligned}
p_{xy} = q(y|x) \cdot r(x \to y)
\end{aligned}
$$

где је $q(y|x)$ горепоменута расподела предлога, односно вероватноћа предлагања $y$ за дато тренутно стање $x$, а $r(x \to y)$ је вероватноћа прихватања предложеног стања y.
Према томе, добијамо:
$$
\begin{aligned}
\frac{r(x \to y)}{r(y \to x)} = \frac{p_{xy}}{q(y|x)} \cdot \frac{q(x|y)}{p_{yx}} = \frac{f(y)q(x|y)}{f(x)q(y|x)}
\end{aligned}
$$
Сада још треба да одредимо вероватноћу прихватања $r$ такву да задовољава наведене услове. Чест избор је:
$$
\begin{aligned}
r(x \to y) = min(1, \frac{f(y)q(x|y)}{f(x)q(y|x)})
\end{aligned}
$$
За овако одабрано $r$ видимо да мора бити $r(x \to y) = 1$ или $r(y \to x) = 1$.
Сада спроведимо алгоритам на већ описани начин.

#### Алгоритам

1. Изаберемо почетно стање $x_0$
2. У свакој итерацији предлажемо нове вредности и прихватамо их или одбацујемо у зависности од $r$

У $i$-тој итерацији:

1. Генеришемо кандидата $y$ на основу расподеле предлога $q(y|x_i)$
2. Рачунамо вероватноћу прихватања $r(x \to y) = min(1, \frac{f(y)q(x|y)}{f(x)q(y|x)})$
3. Генеришемо случајан број $u$ из $\mathcal{U}[0, 1]$ расподеле
  i) Aко је $u \leq r(x_i \to y)$ __прихватамо__ ново стање и постављамо $x_{i+1} = y$
  i) Aко је $u > r(x_i \to y)$ __одбацујемо__ ново стање и постављамо $x_{i+1} = x_i$

Понављамо претходне кораке $N$ пута, где је $N$ велики број. Расподела узорачких вредности $x_0, \dots, x_N$ ће апроксимирати нашу жељену расподелу. Колико треба да буде $N$, односно колико је итерација потребно да би се ефективно проценила жељена расподлела разликује се од случаја до случаја и зависи од неколико фактора, укључујући везу између жељене расподеле и расподеле предлога и жељене тачности процене.

#### Недостаци

Један од најважнијих проблема који се јавља је што су вредности у узорку добијене на овај начин корелисане. Дакле, иако после великог броја итерација добијамо приближно узорак из циљне расподеле, блиске вредности су корелисане, и неће исправно одражавати расподелу.

Додатно, иако се ланац на крају приближава циљној расподели, почетне вредности обично не потичу из ње, па је потребно одбацити одређени број почетних вредности. Дакле, Марковљев ланац се покреће из произвољне тачке и алгоритам се понавља за много итерација све док ово почетно стање не буде “заборављено”. Ови узорци, који се одбацују, познати су као _burn-in_. Преостали скуп прихваћених вредности представља узорак из жељене расподеле.

Као што смо већ поменули, у општем случају не знамо који је број итерација потребан за правилну процену. Такође, не знамо ни коју расподелу предлога одбрати у општем случају - и једно и друго се прилагођавају конкретном проблему. Показало се да алгоритам ради најбоље ако расподела предлога одговара облику жељене расподеле тј. ако је $q(y|x_i) \approx f(y)$.

Додатно, ако се користи нормална расподела као расподела предлога, параметар дисперзије мора бити подешен током _burn-in_ периода. Ако је одабрана дисперзија мала, ланац ће се споро мешати (стопа прихватања ће бити висока, али ће се узастопне вредности кретати споро по узорачком простору и ланац ће споро конвергирати ка жељеној расподели). С друге стране, ако је дисперзија превелика, стопа прихватања ће бити веома ниска, јер је вероватније да предлози леже у регионима мање вероватноће, па ће опет ланац конвергирати веома споро. Обично се подешава диперзија расподеле предлога тако да алгоритам прихвата приближно 30% свих узорака.

Вратимо се на први проблем - блиске вредности су корелисане, а ми обично желимо скуп независних вредности. Ово се може ублажити тако што ћемо одбацити већину вредности и узети сваку $k$-ту вредност у узорак, за неко $k$, које се обично одређује испитивањем аутокорелације између суседних вредности. Аутокорелација се може смањити повећањем ширине скока (која је повезана са дисперзијом расподеле скока, односно расподеле предлога), међутим, то ће повећати и вероватноћу одбацивања предлога. Као што смо већ рекли, превелика или премала ширина скока ће довести до спорог мешања, тако да ће бити потребан велики број итерација да би се добила разумна процена жељене расподеле.

Међутим, и уз све проблеме и недостатке, MCMC методе се јако често користе и јако су моћне. Једна од главних предности је то што, док већина једноставних метода узорковања, које дају независне узорке, прати од проблема димензионалности, Метрополис-Хастингс и сличне методе, немају тај проблем у толикој мери, па су стога често једино решење када желимо да узоркујемо из расподела великих димензија.

Када узоркујемо из вишедимензионих расподела, класични Метрополис-Хастингс алгоритам у сваком кораку укључује избор нове вишедимензионалне тачке узорка. Међутим, када је број димензија велики, проналажење одговарајуће расподеле предлога може да буде тешко, јер ширина скока мора бити добро одабрана за све компоненте одједном да би се избегло превише споро мешање. То је често тешко урадити, па се у таквим ситуацијама прелази на Гибсово узорковање.

## Гибсов алгоритам{#id7}

#### Идеја

Гибсово узорковање је једна од MCMC метода за добијање узорака који су апроксимативно из вишедимензионе расподеле вероватноће, када је директно узорковање из ње тешко. То је MCMC алгоритам који апроксимира заједничку расподелу више случајних величина узимањем узорака из условне расподеле сваке променљиве.

Гибсово узорковање је применљиво када заједничка расподела није експлицитно позната или је тешко узорковати из ње директно, али је условна расподела сваке променљиве позната и лако је (или барем лакше) из ње узорковати. Главна идеја је да се разбије проблем узорковања из вишедимензионе расподеле на серије узорака из условних расподела мањих димензија. Гибcов алгоритам за узорковање генерише вредност из расподеле сваке променљиве под условом тренутних вредности других променљивих. Као и код других MCMC алгоритама, Гибсовим узорковањем се генерише Марковљев ланац, тако да је свака узоркована вредност повезана са блиским вредностима (зато се мора пазити ако су потребни независни узорци!). Дакле, може се показати да низ узорака чини Марковски ланац, а стационарна расподела тог Марковског ланца је тражена заједничка расподела.

Низ узорака добијених овом методом се може користити за апроксимацију заједничке расподеле (нпр. за генерисање хистограма расподеле), за апроксимирање маргиналне расподеле неке променљиве, или скупа променљивих, или рачунање интеграла (нпр. очекивање неке променљиве). Обично неке од променљивих одговарају опсервацијама чије су вредности познате, па не морају бити узорковане.

Уобичајено је да узорковане вредности са почетка ланца (_burn-in_ период) одбацују, јер вероватно неће тачно представљати жељену расподелу. Ипак, показано је да употреба дужег ланца доводи до добрих процена праве жељене расподеле.

Гибсово узорковање се обично користи као помоћ код статистичког закључивања, а његова можда најважнија примена односи се на процењивање апостериорне расподеле код Бајесовог закључивања.

Гибсово узорковање је предложено раних 90-их и фундаментално је изменило Бајесовско израчунавање.

#### Алгоритам

Идеја код Гибсовог узорковања је генерисање узорака тако што се пролази кроз сваку променљиву и узорковање врши из њене условне расподеле са преосталим променљивама фиксираним на неке вредности.

На пример, размотримо случајне величине $X_1, X_2, X_3$.

Почињемо тако што ћемо их све поставити на неке почетне вредности $x_1^{(0)}, x_2^{(0)}, x_3^{(0)}$. То су често вредности добијене узорковањем из априорне расподеле.

У $i$-тој итерацији, узоркујемо
$$
\begin{aligned}
x_1^{(i)} \sim p(x_1|X_2=x_2^{(i-1)}, X_3=x_3^{(i-1)})
\end{aligned}
$$
па онда:
$$
\begin{aligned}
x_2^{(i)} \sim p(x_2|X_1=x_1^{(i)}, X_3=x_3^{(i-1)})
\end{aligned}
$$
и на крају:
$$
\begin{aligned}
x_3^{(i)} \sim p(x_3|X_1=x_1^{(i)}, X_2=x_2^{(i)})
\end{aligned}
$$

Овај процес се наставља до конвергенције (док вредности из узорка не буду имале исту расподелу као да су узорковане из праве заједничке расподеле).

Опишимо сада кораке Гибсовог алгоритма.

Претпоставимо да желимо да добијемо $N$ узорака из заједничке расподеле случајног вектора $\theta = (\theta_1, \dots, \theta_k)$. Алгоритам се одвија на следећи начин:

1. На почетку је потребно иницијализовати ланац. Дакле, почињемо са неком иницијалном вредношћу $\theta^{(1)} = (\theta_1^{(1)}, \dots, \theta_k^{(1)})$
Затим, у свакој итерацији примењујемо следеће:
2. Претпоставимо да имамо узорак $\theta^{(i)}$ и желимо следећи узорак $\theta^{(i+1)} = (\theta_1^{(i+1)}, \dots, \theta_k^{(i+1)})$. Пошто је $\theta^{(i+1)}$ вектор, потребно је да узоркујемо сваку његову компоненту. То радимо на следећи начин:
Прођемо кроз сваку условну расподелу, узорковањем за $i = 1, 2, \dots$
$$
\begin{aligned}
\theta_1^{(i+1)} \sim p(\theta_1|\theta_2^{(i)}, \theta_3^{(i)}, \dots, \theta_k^{(i)})\\
\theta_2^{(i+1)} \sim p(\theta_2|\theta_1^{(i+1)}, \theta_3^{(i)}, \dots, \theta_k^{(i)})\\
\end{aligned}
$$
$$
\begin{aligned}
\vdots
\end{aligned}
$$
$$
\begin{aligned}
\theta_k^{(i+1)} \sim p(\theta_k|\theta_1^{(i+1)}, \theta_2^{(i+1)}, \dots, \theta_{k-1}^{(i+1)})\\
\end{aligned}
$$
Приметимо да се у сваком кораку користи најскорија вредност $\theta_j$. Дакле, користимо до сада узорковане компоненте вектора $\theta^{(i+1)}$, а оне које још увек нису узорковане преносимо из вектора $\theta^{(i)}$. Да бисмо ово постигли, узоркујемо компоненте по реду, почевши од прве.
3. Понављамо корак (2) $N$ пута.

Дакле, морамо бити у стању да узоркујемо из сваке условне расподеле да бисмо могли да користимо Гибсово узорковање. Олакшавајућа околност је та што је условна расподела једне променљиве (у односу на све остале) пропорционална заједничкој расподели:
$$
\begin{aligned}
p(\theta_j|\theta_1,\dots,\theta_{j-1},\theta_{j+1},\dots,\theta_k) = \frac{p(\theta_1,\dots,\theta_k)}{p(\theta_1,\dots,\theta_{j-1},\theta_{j+1},\dots,\theta_k)} \propto p(\theta_1,\dots,\theta_k)
\end{aligned}
$$

Дакле, да би се одредио облик условне расподеле за појединачну компоненту, најједноставније је заједничку расподелу разложити на појединачне условне расподеле и игнорисати све факторе који не зависе од те компоненте, а затим поново додати константу нормализације на крају, по потреби (ако је расподела дискретна, израчунају се појединачне вероватноће свих могућих вредности које може узети та случајна величина, а затим се сабирају како би се утврдила константа нормализације, ако је расподела непрекидна и познатог облика, константа нормализације се такође лако израчунава, а у другим случајевима, константа нормализације се обично може игнорисати, јер већина метода узорковања то не захтева).

Након пуно циклуса (тј. за велико $N$), узорковане вредности ће апроксимирати случајне узорке из заједничке расподеле $\theta = (\theta_1, \dots, \theta_k)$.

Дакле, у случају бајесовских метода, у овом алгоритму не узимамо узорке из саме апостериорне расподеле. Уместо тога, симулирамо узорке тако што пролазимо кроз све апостериорне условне расподеле, за сваку од случајних величина, када су преостале фиксиране. Почетне вредности променљивих могу се одредити насумично или уз помоћ неког алгоритма који даје бржу конвергенцију, а није потребно одредити почетну вредност за прву променљиву. Будући да на почетку иницијализујемо случајним почетним вредностима, узорци симулирани при почетним итерацијама не морају бити репрезентативни за праву апостериорну расподелу. Међутим, теорија MCMC метода гарантује да ће стационарна расподела узорака генерисаних овим алгоритмом бити циљна апостериорна расподела.

Из тог разлога, MCMC алгоритми се обично покрећу за велики број итерација (у нади да ће се конвергенција ка циљној апостериорној расподели постићи). Пошто узорци из почетних итерација нису блиски онима из апостериорне расподеле,  и овде је пракса да се игнорише одређени број узорака на почетку (_burn-in_). Такође, често је да се узме у обзир само сваки $n$-ти када се, рецимо, усредњавају вредности да би се израчунало очекивање. На пример, првих 1000 узорака може бити игнорисано, а онда је сваки 100. узорак узет у просек, док се остало одбацује. Разлогe за то смо већ прокоментарисали када смо говорили о недостацима MCMC алгоритама.

# Евалуација и избор модела{#id8}

Уколико имамо на располагању коначан број модела, од којих је потребно користити један, поставља се питање избора модела, које се решава тако што се на неки начин евалуирају сви расположиви модели и изабере се најбољи.

Најједноставнија техника евалуације модела је помоћу скупа за тестирање. Посматрамо моделе $M_1, M_2,...,M_n$. Податке делимо на скуп за обучавање и скуп за тестирање. Скуп за обучавање је обично већи - најчешће две трећине података и на њему се одређују апроксимације наших модела, тј. добијамо моделе $M'_1,M'_2,...,M'_n$ који се онда примењују на скуп за тестирање, чиме се добијају њихова предвиђања, која се онда неком мером квалитета могу упоредити са тачним вредностима циљне променљиве. Модел, чија апроксимација има најмању грешку, проглашавамо за најбољи модел.

Овакав приступ има доста мана. Прво, неки подаци су изабрани да буду у скупу за обучавање, а неки да буду у скупу за тестирање. Од начина на који је извршена подела зависиће и оцена квалитета. За различите поделе, ова оцена може значајно варирати. На пример, ако скуп за тестирање садржи само инстанце са највишом (или најнижом) вредношћу циљне променљиве, грешка оцене ће бити врло велика.

Одговор на неке од претходних проблема је техника К-слојне унакрсне валидације (енг. K-fold cross-validation). Спроводи се на следећи начин:
Посматрамо модел $M$ и хоћемо да израчунамо његову грешку. Скуп података $D$ делимо на $K$ приближно једнаких подскупова, такозваних слојева $\{S_1,...,S_k\}$. Обучавамо модел $M'_i$, $i = 1,...,K$ (сви ови модели су апроксимације модела $M$) користећи скуп $D/S_i$, $i = 1,...,K$ и извршавамо предвиђање добијеним моделом на скуповима $S_i$, а затим израчунамо грешку предвиђања. На крају саберемо добијених $K$ грешака, и на тај начин добијемо грешку нашег модела $M$. Овај поступак понављамо за сваки од модела $M_1,...M_n$ и за најбољи проглашавамо онај који има најмању грешку.

Предност ове технике у односу на претходну је мања варијанса оцене грешке услед тога што се оцена грешке рачуна на већој количини података. Дакле, оцена грешке је поузданија. Мана овог приступа је што се модел не обучава једном, него $K$ пута, што може бити временски захтевно. Напоменимо још да се у пракси за $K$ најчешће користе вредности 5 и 10.


# Пример

У овом поглављу ћемо кроз пример илустровати вишеструку бајесовску линеарну регресију. Упоредићемо класични и бајесовски приступ. При томе, у бајесовском приступу ћемо полазити од различитих априорних расподела, а кад не будемо у могућности да нађемо апостериорну расподелу, користићемо Гибсов алгоритам за креирање узорка из апостериорне расподеле.

Биће приказани:

* [Поставка проблема](#id9)
  + [Класична линеарна регресија](#id10)
  + [Бајесовска линеарна регресија](#id11)
    - [Модел 1](#id12)
    - [Модел 2](#id13)
    - [Модел 3](#id14)
    - [Модел 4](#id15)
  + [Поређење](#id16)
* [Закључак](#id17)

## Поставка проблема{#id9}

Скуп података који ћемо користити у овом примеру је Boston из пакета MASS и може се пронаћи у R-у. Подаци су сакупљени средином 70-их година 20. века. Скуп се састоји од 506 опсервација које одговарају насељима у Бостону. Свакој опсервацији одговара следећих 14 променљивих:

```{r echo=FALSE, warning = FALSE}
library(kableExtra)

table <- rbind(c(1, "crim", "стопа криминала"), c(2, "zn", "удео стамбеног земљишта предвиђеног за парцеле веће од 23 ара"), c(3, "indus", "удео пословног простора"), c(4, "chas", "1 ако река протиче кроз насеље, иначе 0"), c(5, "nox", "концентрација нитроген оксида"), c(6, "rm", "просечан број соба у кући"), c(7, "age", "просечна старост кућа"), c(8, "dis", "просечна удаљеност од 5 бостонских центара за запошљавање"), c(9, "rad", "индекс приступачности главних аутопутева"), c(10, "tax", "висина пореза на имовину (по 10000 долара)"), c(11, "ptratio", "однос броја ученика и наставника"), c(12, "black", "$1000*(Bk-0.63)^2$, где је $Bk = \\frac{број \\hspace{0.2cm} Афроамериканаца}{број \\hspace{0.2cm} свих \\hspace{0.2cm} становника}$"), c(13, "lstat", "проценат становништва које припада нижем слоју"), c(14, "medv", "просечна цена куће, изражена у хиљадама долара"))
knitr::kable(table, format = "latex", escape = TRUE)
table %>%
  kbl() %>%
  kable_styling()
```

Наш циљ је да моделујемо зависност medv од осталих променљивих. <br/>
Како су подаци изражени у различитим јединицама, прво ћемо извршити стандардизацију података, односно од сваке вредности у табели ћемо одузети средњу вредност колоне у којој се налази та вредност, а затим поделити са стандардном девијацијом те колоне. На тај начин, у свакој колони добијамо податке центриране око нуле, са јединичном дисперзијом. То радимо користећи уграђену функцију scale.

```{r}
set.seed(11)
library(MASS)
podaci <- Boston
ocekivanje <- apply(podaci, 2, mean)
st_devijacija <- apply(podaci, 2, sd)
standardizovani_podaci <- scale(podaci, center = ocekivanje, scale = st_devijacija)
```

На следећим графицима приказана је међусобна зависност стандардизованих података. Конкретно, посматрамо зависност променљиве medv од осталих променљивих, користећи функције ggplot и geom_point из пакета ggplot2.

```{r, warning = FALSE}
library(ggplot2)
g1 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = crim, y = medv)) +
  geom_point(color = "red", size = 0.8) + xlim(c(-1, 8))
g2 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = zn, y = medv)) +
  geom_point(color = "green", size = 0.8)
g3 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = indus, y = medv)) +
  geom_point(color = "red", size = 0.8)
g4 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = chas, y = medv)) +
  geom_point(color = "green", size = 0.8)
g5 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = nox, y = medv)) +
  geom_point(color = "red", size = 0.8)
g6 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = rm, y = medv)) +
  geom_point(color = "green", size = 0.8)
g7 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = age, y = medv)) +
  geom_point(color = "red", size = 0.8)
g8 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = dis, y = medv)) +
  geom_point(color = "green", size = 0.8) + xlim(c(-1.5, 3.5))
g9 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = rad, y = medv)) +
  geom_point(color = "red", size = 0.8)
g10 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = tax, y = medv)) +
  geom_point(color = "green", size = 0.8)
g11 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = ptratio, y = medv)) +
  geom_point(color = "red", size = 0.8)
g12 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = black, y = medv)) +
  geom_point(color = "green", size = 0.8)
g13 <- ggplot(data = as.data.frame(standardizovani_podaci), aes(x = lstat, y = medv)) +
  geom_point(color = "red", size = 0.8)

library(pdp)
grid.arrange(g1, g2, g3, g4, ncol = 2)
grid.arrange(g5, g6, g7, g8, ncol = 2)
grid.arrange(g9, g10, g11, ncol = 2)
```

## Класична линеарна регресија{#id10}

Прво ћемо размотрити класичан линеарни регресиони модел. Креирамо га, методом најмањих квадрата, коришћењем функције $lm$:

```{r}
lin_regr <- lm(medv ~ ., data = podaci)
summary(lin_regr)
```
На основу вредности колоне $Pr(>|t|)$ закључујемо да indus и age нису значајни предиктори. Такође, посматрајући колону $Pr(>|t|)$, видимо да су $lstat, rm$ и $dis$ најзначајнији предиктори. <br/>
Због тога ћемо да креирамо модел без променљивих $indus$ и $age$.

```{r}
podaci_znacajni <- Boston[, -c(3,7)]
lin_regr2 <- lm(medv ~ ., data = podaci_znacajni)
summary(lin_regr2)
```

## Бајесовска линеарна регресија{#id11}

Сада прелазимо на бајесовски приступ линеарној регресији. Креираћемо три модела и упоредићемо који је бољи методом унакрсне валидације. <br/>


Размотримо прво општи случај. Претпоставимо да имамо $n$ опсервација и $p$ предиктора. Означимо циљну променљиву са 
$$\begin{align}
y = (y_1,...,y_n),
\end{align}$$
а предикторе са 
$$\begin{align}
X=(1,x_1,...,x_{p}),
\end{align}$$
где су $1, x_1,...,x_p$ колоне матрице $X$. Колона јединица означава слободан члан. Вектор коефицијената означимо са 
$$\begin{align}
\beta = (\beta_0, \beta_1,...,\beta_{p}).
\end{align}$$
У бајесовском приступу, коефицијенте регресије посматрамо као случајне величине које имају априорну расподелу. На основу датих података рачунамо апостериорну расподелу сваког коефицијента. Конкретне вредности коефицијената добијамо у зависности од изабране функције губитака.
Дакле, имамо: 
$$\begin{align}
y = X\beta + \varepsilon
\end{align}$$
где је $\varepsilon$ вектор резидуала. <br/>

### Модел 1{#id12}

У првом моделу претпостављамо да су $y_i|\Theta,X$ међусобно независни, и
$$\begin{align}
E(\varepsilon_i)=0,\\ 
D(\varepsilon_i)=\sigma^2,
\end{align}$$

$$\begin{align}
y|\beta,X,\sigma^2 \sim \mathcal{N}(X\beta, \sigma^2 E)
\end{align}$$
где је $\mathcal{N}(X\beta, \sigma^2 E)$ $n$-димензиона нормална расподела. Тада ће и резидуали бити независни и нормално расподељени. Вектор непознатих параметара је 
$$\begin{align}
\Theta = (\beta_0,...,\beta_p,\sigma^2).
\end{align}$$
Стандардна неинформативна расподела за $\Theta$ је неправа расподела која је униформна за $(\beta, log\sigma)$, односно 
$$\begin{align}
\pi(\beta, \sigma^2) \propto \frac{1}{\sigma^2}
\end{align}$$. <br/>
При овим условима можемо да нађемо апостериорну расподелу параметра $\Theta$ (апостериорна расподела ће бити права ако су испуњени услови $n>p$ и $rang(X) = p$), а самим тим и маргиналне апостериорне расподеле. Добија се да $\beta|y$ има $(p+1)$-димензиону Студентову расподелу. Међутим, у пракси се ретко узоркује директно из Студентове расподеле, већ се користе симулације и то на следећи начин. Из заједничке апостериорне расподеле се добијају апостериорне маргиналне расподеле
$$\begin{align}
\beta|\sigma^2, y \sim \mathcal{N}(\hat{\beta}, \sigma^2 (X^T X)^{-1})
\end{align}$$ 
$$\begin{align}
\sigma^2| y \sim \gamma^{-1}\left(\frac{n-p}{2},\frac{(n-p)s^2}{2}\right)
\end{align}$$
где је 
$$\begin{align}
\hat{\beta}=(X^T X)^{-1}X^T y
\end{align}$$
$$\begin{align}
s^2 = \frac{(y-X\hat{\beta})^T(y-X\hat{\beta})}{n-p}
\end{align}$$ 
Прво се симулира вредност $\sigma^2$ из расподеле за $\sigma^2|y$, а затим се симулира вредност $\beta$ из расподеле за $\beta|\sigma^2,y$. Та два корака се понављају онолико пута колики узорак желимо. Илуструјмо разматрано на нашем примеру, користећи пакет $LearnBayes$ и функцију $blinreg$ која враћа узорак из апостериорне расподеле од $\beta$ при условима које смо претпоставили. Прво разматрамо који су нам предиктори значајни рачунајући $95%$-ни интервал највеће апостериорне густине, користећи стандардизоване податке. Ако интервал НАГ садржи нулу, онда тај предиктор сматрамо безначајним.

```{r, message=FALSE}
library(LearnBayes)
y <- standardizovani_podaci[,14]
X <- matrix(nrow = 506, ncol = 14)
X[,1] <- rep(1,506)
X[,-1] <- standardizovani_podaci[,-14]
uzorak <- blinreg(y, X, 5000) #vadimo uzorak velicine 5000
koef <- uzorak$beta
colnames(koef) <- c("slobodan_clan","crim", "zn", "indus", "chas", "nox", "rm", "age", "dis",
                    "rad", "tax", "ptratio", "black", "lstat") 
intervali <- apply(koef, 2, quantile, probs = c(0.025, 0.975))
intervali
```

Дакле, као и у случају обичне линеарне регресије, добијамо да су indus и age безначајни предиктори, па ћемо да креирамо модел без тих предиктора. Конкретне вредности коефицијената рачунамо као очекивање апостериорне расподеле.

```{r}
podaci <- as.matrix(podaci)
X[,-1] <- podaci[,-14]
X <- X[, -c(4,8)]
y <- podaci[,14]
uzorak <- blinreg(y, X, 5000)
koef <- uzorak$beta
colnames(koef) <- c("slobodan_clan","crim", "zn", "chas", "nox", "rm", "dis",
                    "rad", "tax", "ptratio", "black", "lstat")
koeficijenti <- apply(koef, 2, mean)
koeficijenti
```

### Модел 2{#id13}

Други модел базирамо на следећим претпоставкама. Дакле, имамо: 
$$\begin{align}
y = X\beta + \varepsilon,
\end{align}$$
где је $\varepsilon$ вектор резидуала. Претпостављамо да су резидуали независни и нормално расподељени, тј.
$$\begin{align}
\mathcal{N}(0, \sigma^2)
\end{align}$$
Претпостављамо да вектор $\beta$ има $(p+1)$-димензиону нормалну априорну расподелу, а параметар $\sigma^2$ инверзну гама расподелу за априорну, при чему су $\beta$ и $\sigma^2$ независне. <br/>
Узорак из апостериорне расподеле генеришемо користећи функцију $MCMCregress$ из пакета $MCMCpack$. Ова функција враћа узорак из апостериорне расподеле баш за априорне расподеле које смо претпоставили, и то ради помоћу Гибсовог алгоритма, јер је тешко наћи аналитички облик апостериорне расподеле. Аргументи функције MCMCregress су: $b_0$, $B_0$, $sigma.mu$, $sigma.var$, $burnin$, $mcmc$... Помоћу $b_0$ и $B_0$ задајемо очекивање и дисперзију параметара $\beta$, при чему је $B_0$ реципрочна вредност дисперзије. а помоћу $sigma.mu$ и $sigma.var$ задајемо очекивање и дисперзију гама расподеле параметра $\sigma$. $mcmc$ означава величину узорка, а burnin означава колико почетних итерација одбацујемо.

```{r, warning = FALSE, message = FALSE}
library(MCMCpack)
X1 <- podaci[,-14]
X1 <- X1[, -c(3,7)]
koef2 <- MCMCregress(y~X1, b0=0, B0 = 0.001,
	      sigma.mu = 5, sigma.var = 25, burnin = 1000, mcmc = 5000, data = podaci_znacajni)
colnames(koef2) <- c("slobodan_clan","crim", "zn", "chas", "nox", "rm", "dis",
                     "rad", "tax", "ptratio", "black", "lstat", "sigma")
koeficijenti2 <- apply(koef2, 2, mean)
koeficijenti2

```

### Модел 3{#id14}

Трећи модел се разликује од другог само у дисперзији нормалне расподеле коефицијената бета.
```{r, warning = FALSE, message = FALSE}
koef3 <- MCMCregress(y ~ X1, b0 = 0, B0 = 0.1,
	      sigma.mu = 5, sigma.var = 25, burnin = 1000, mcmc = 5000, data = podaci_znacajni)
colnames(koef3) <- c("slobodan_clan","crim", "zn", "chas", "nox", "rm", "dis",
                     "rad", "tax", "ptratio", "black", "lstat", "sigma")
koeficijenti3 <- apply(koef3, 2, mean)
koeficijenti3
```
### Модел 4{#id15}

Сада ћемо илустровати случај у којем имамо добре информативне априорне расподеле. То се у пракси ради тако што се искористе претходна искуства, али ми ћемо то илустровати тако што ћемо искористити исте податке и за креирање априорних расподела и за добијање апостериорних расподела. Дакле, претпостављамо да коефицијенти имају нормалне расподеле са очекивањима која су једнака коефицијентима добијеним првим моделом, и са дисперзијама једнаким нпр. квадратима тих очекивања помноженим са 10.
```{r, warning = FALSE, message = FALSE}
koef4 <- MCMCregress(y ~ X1, b0 = koeficijenti, B0 = 10/koeficijenti^2,
	      sigma.mu = 5, sigma.var = 25, burnin = 1000, mcmc = 5000, data = podaci_znacajni)
colnames(koef4) <- c("slobodan_clan","crim", "zn", "chas", "nox", "rm", "dis",
                     "rad", "tax", "ptratio", "black", "lstat", "sigma")
koeficijenti4 <- apply(koef4, 2, mean)
koeficijenti4
```

### Поређење{#id16}

На следећим графицима су упоређене оцењене апостериорне густине параметара из првог и другог модела. Црвеном бојом су приказане густине из првог модела, а зеленом густине из другог модела.

```{r}
g1 <- ggplot(as.data.frame(koef), aes(x=crim)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=crim), col="green")
g2 <- ggplot(as.data.frame(koef), aes(x=zn)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=zn), col="green")
g3 <- ggplot(as.data.frame(koef), aes(x=chas)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=chas), col="green")
g4 <- ggplot(as.data.frame(koef), aes(x=nox)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=nox), col="green") 
g5 <- ggplot(as.data.frame(koef), aes(x=rm)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2),mapping= aes(x=rm), col="green") 
g6 <- ggplot(as.data.frame(koef), aes(x=dis)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=dis), col="green")
g7 <- ggplot(as.data.frame(koef), aes(x=rad)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=rad), col="green")
g8 <- ggplot(as.data.frame(koef), aes(x=tax)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=tax), col="green")
g9 <- ggplot(as.data.frame(koef), aes(x=ptratio)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=ptratio), col="green")
g10 <- ggplot(as.data.frame(koef), aes(x=black)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=black), col="green")
g11 <- ggplot(as.data.frame(koef), aes(x=lstat)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef2), mapping=aes(x=lstat), col="green") 
grid.arrange(g1, g2, g3, g4, ncol = 2)
grid.arrange(g5, g6, g7, g8, ncol = 2)
grid.arrange(g9, g10, g11, ncol = 2)
```
<br/> 
Уочавамо да су оцењене апостериорне расподеле веома сличне. <br/> 


Израчунајмо средњеквадратну грешку првог модела, користећи унакрсну валидацију.

```{r}
greske = rep(0, 5)
for(i in 1:5) 
{
  indeksi <- c()
  clan_niza <- i
  while(clan_niza < 507)
  {
    indeksi <- c(indeksi, clan_niza)
    clan_niza <- clan_niza + 5
  }
  trening_podaci <- X[-indeksi,]
  test_podaci <- X[indeksi,]
  uzorak1 <- blinreg(y[-indeksi], trening_podaci, 5000)
  koef1 <- uzorak1$beta
  koeficijenti1 <- apply(koef1, 2, mean)
  y_predikcije <- test_podaci %*% koeficijenti1
  greske[i] <- mean((y[indeksi] - y_predikcije)^2)
}
greska <- mean(greske)
greska

```


Сада рачунамо средњеквадратну грешку другог модела, користећи унакрсну валидацију.

```{r}
greske2 = rep(0, 5)
for(i in 1:5) 
{
  indeksi <- c()
  clan_niza <- i
  while(clan_niza < 507)
  {
    indeksi <- c(indeksi, clan_niza)
    clan_niza <- clan_niza + 5
  }
  trening_podaci <- X1[-indeksi,] #razlika izmedju X i X1 je u tome sto X ima i kolonu jedinica 
  test_podaci <- X[indeksi,]
  koef1 <- MCMCregress(y[-indeksi]~trening_podaci, b0=0, B0 = 0.001,
	      sigma.mu = 5, sigma.var = 25, burnin = 1000, mcmc = 5000,
	      data = podaci_znacajni[-indeksi,])
  koeficijenti1 <- apply(koef1[, -13], 2, mean) #iz koef1 izbacujemo kolonu sigma
  y_predikcije <- test_podaci %*% koeficijenti1
  greske2[i] <- mean((y[indeksi] - y_predikcije)^2)
}
greska2 <- mean(greske2)
greska2

```

На следећим графицима су упоређене оцењене апостериорне густине параметара из првог и трећег модела. Црвеном бојом су приказане густине из првог модела, а плавом густине из трећег модела.

```{r}
g1 <- ggplot(as.data.frame(koef), aes(x=crim)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=crim), col="blue")
g2 <- ggplot(as.data.frame(koef), aes(x=zn)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=zn), col="blue")
g3 <- ggplot(as.data.frame(koef), aes(x=chas)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=chas), col="blue")
g4 <- ggplot(as.data.frame(koef), aes(x=nox)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=nox), col="blue") 
g5 <- ggplot(as.data.frame(koef), aes(x=rm)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3),mapping= aes(x=rm), col="blue") 
g6 <- ggplot(as.data.frame(koef), aes(x=dis)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=dis), col="blue")
g7 <- ggplot(as.data.frame(koef), aes(x=rad)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=rad), col="blue")
g8 <- ggplot(as.data.frame(koef), aes(x=tax)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=tax), col="blue")
g9 <- ggplot(as.data.frame(koef), aes(x=ptratio)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=ptratio), col="blue")
g10 <- ggplot(as.data.frame(koef), aes(x=black)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=black), col="blue")
g11 <- ggplot(as.data.frame(koef), aes(x=lstat)) + geom_density(col="red") + 
  geom_density(as.data.frame(koef3), mapping=aes(x=lstat), col="blue") 
grid.arrange(g1, g2, g3, g4, ncol = 2)
grid.arrange(g5, g6, g7, g8, ncol = 2)
grid.arrange(g9, g10, g11, ncol = 2)
```
<br/> 
Примећујемо да густине појединих параметара из трећег модела знатно одступају од првог модела, што узрокује сумњу да је трећи модел лош. Да бисмо потврдили своје сумње, довољно је да израчунамо грешку трећег модела, користећи унакрсну валидацију. 
```{r}
greske3 = rep(0, 5)
for(i in 1:5) 
{
  indeksi <- c()
  clan_niza <- i
  while(clan_niza < 507)
  {
    indeksi <- c(indeksi, clan_niza)
    clan_niza <- clan_niza + 5
  }
  trening_podaci <- X1[-indeksi,] 
  test_podaci <- X[indeksi,]
  koef1 <- MCMCregress(y[-indeksi]~trening_podaci, b0 = 0, B0 = 0.1,
	      sigma.mu = 5, sigma.var = 25, burnin = 1000, mcmc = 5000,
	      data = podaci_znacajni[-indeksi,])
  koeficijenti1 <- apply(koef1[, -13], 2, mean) 
  y_predikcije <- test_podaci %*% koeficijenti1
  greske3[i] <- mean((y[indeksi] - y_predikcije)^2)
}
greska3 <- mean(greske3)
greska3

```

 <br/>  Дакле, трећи модел је заиста гори, а то је последица лошег избора априорних расподела. Наиме смањивањем дисперзија априорних расподела, повећали смо њихову информативност, и то у погрешном смеру, па смо добили лошије апостериорне расподеле. <br/>
 
Рачунамо грешку четвртог модела.
```{r}
greske4 = rep(0, 5)
for(i in 1:5) 
{
  indeksi <- c()
  clan_niza <- i
  while(clan_niza < 507)
  {
    indeksi <- c(indeksi, clan_niza)
    clan_niza <- clan_niza + 5
  }
  trening_podaci <- X1[-indeksi,] 
  test_podaci <- X[indeksi,]
  koef1 <- MCMCregress(y[-indeksi]~trening_podaci, b0 = koeficijenti, B0 = 10/koeficijenti^2,
	      sigma.mu = 5, sigma.var = 25, burnin = 1000, mcmc = 5000,
	      data = podaci_znacajni[-indeksi,])
  koeficijenti1 <- apply(koef1[, -13], 2, mean) 
  y_predikcije <- test_podaci %*% koeficijenti1
  greske4[i] <- mean((y[indeksi] - y_predikcije)^2)
}
greska4 <- mean(greske4)
greska4

```


# Закључак{#id17}

У првом поглављу представљени су теоријски резултати који се налазе иза сваке бајесовске анализе података.
Друго поглавље посвећено је илустрацији бајесовске линеарне регресије. 
Модели су креирани на истим, реалним подацима.
У првом примеру приказује се кратко обична линеарна регресија.
У даљим примерима илустрована је бајесовска линеарна регресија, и то за различите изборе априорних расподела.
Тако добијени модели су на крају упоређени у средњеквадратном смислу, методом унакрсне валидације.
Од суштинског значаја су се показале MCMC методе које омогућавају узорковање из произвољних апостериорних расподела, без да је неопходан њихов аналитички облик. 

# Референце


